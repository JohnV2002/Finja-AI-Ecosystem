# ğŸŒ Web Crawler API

Ein schlanker, schneller und sicherer Web-Crawler, der Suchanfragen anonym Ã¼ber **DuckDuckGo (DDGS)** via **Tor** stellt â€”  
und bei zu wenigen Treffern automatisch auf **Google-HTML-Scraping** zurÃ¼ckfÃ¤llt.  
Wenn gar nichts gefunden wird, liefert er als Notfall ein **Wikipedia-Fallback (Tabby-Katzen)**.  
Perfekt als **externer Web-Suchdienst fÃ¼r Open WebUI**. ğŸ•µï¸â€â™€ï¸ğŸ’»

---

## âš ï¸ Recht, Haftung & Datenschutz (bitte lesen)

- **Zweck**: Dieses Projekt ist **nur fÃ¼r Tests & Lernzwecke** gedacht.
- **Google-Scraping**: Das automatische Abfragen von Google **verstÃ¶ÃŸt gegen deren Nutzungsbedingungen (TOS)**. Die Nutzung erfolgt **auf eigene Gefahr** und kann zu **IP-Sperren, Captchas oder rechtlichen Schritten** fÃ¼hren.
- **Haftungsausschluss**: Ich stelle nur den Code bereit. **Ich hafte nicht** fÃ¼r deine Nutzung, daraus folgende Konsequenzen, Datenverluste oder mÃ¶gliche DSGVO-VerstÃ¶ÃŸe.
- **Datenspeicherung (Crawler)**: Der Crawler selbst speichert **keine Daten dauerhaft**, abgesehen von temporÃ¤ren Logs wÃ¤hrend der AusfÃ¼hrung.
- **Datenspeicherung (Open WebUI)**: Wenn du den Crawler in **Open WebUI** einbindest, speichert Open WebUI die Suchergebnisse in seiner internen Vektor-Datenbank. Bei aktivem **"Adaptive Memory v4"** kÃ¶nnen extrahierte Informationen zusÃ¤tzlich im Memory-Server landen.
    - â†’ **Bei Unsicherheit:** Deaktiviere das "Adaptive Memory" Plugin in Open WebUI.

---

## âœ¨ Features

- **Hybrid-Suche**: zuerst DuckDuckGo (`ddgs`) via **Tor** â†’ wenn zu wenige Treffer: **Google-Fallback** - **Wikipedia-Fallback**: Wenn wirklich nichts gefunden wird â†’ `https://de.wikipedia.org/wiki/Tabby`
- **API-Server (FastAPI)**: JSON-Endpoint `POST /search`
- **ZufÃ¤llige User-Agents** pro Request (erschwert Blocking)
- **Zugriffsschutz** via **Bearer-Token** (aus `.env`, verpflichtend fÃ¼r Open WebUI)
- **Parsing** via BeautifulSoup (Titel, Link, Snippet)
- **Konfigurierbare Pausen** beim Google-Fallback (minimiert Ban-Risiko)
- **Bereit fÃ¼r Docker & Compose** (kein lokales Python-Setup nÃ¶tig)

---

## ğŸ“ Projektstruktur

- `.env` â†’ enthÃ¤lt deinen geheimen `BEARER_TOKEN`
- `docker-compose.yml`
- `Dockerfile`
- `requirements.txt`
- `main.py` â†’ aktiver Hybrid-Crawler (Tor + DDGS + Google-Fallback)
- `generate_token.py` â†’ Token-Generator (optional; nur zur Token-Erzeugung)

---

## ğŸ³ Setup mit Docker (empfohlen, **kein** lokales Python nÃ¶tig)

### 1. Repository klonen

```bash
git clone [https://github.com/JohnV2002/Finja-AI-Ecosystem/finja-Open-Web-UI/finja-web-crawler.git](https://github.com/JohnV2002/Finja-AI-Ecosystem/finja-Open-Web-UI/finja-web-crawler.git)
cd finja-web-crawler
```

### 2. `.env` anlegen (Zugriffsschutz aktivieren)

Erstelle/Ã¶ffne die Datei `.env` im Projektordner und setze ein geheimes Token:
```env
BEARER_TOKEN=mein-sicheres-super-token
```
âš ï¸ **Pflicht fÃ¼r Open WebUI:** Ohne gÃ¼ltigen Token lÃ¤sst sich der externe Crawler in Open WebUI nicht speichern.
âš ï¸ **SIEHE WEITERUNTEN: Sichere Token erstellen fÃ¼r wie das geht**

### 3. Starten (Docker Compose)
```bash
docker compose up --build -d
```
Die API ist nun unter `http://127.0.0.1:8080` erreichbar (je nach Port-Mapping in `docker-compose.yml`).
**Hinweis:** Beim ersten Start kann es etwas dauern, bis der Tor-Dienst vollstÃ¤ndig initialisiert ist.

---

### ğŸ” Sicheren Token erstellen (optional, aber empfohlen)
Dein Token sollte 64 Zeichen lang sein und nur Buchstaben enthalten (Aâ€“Z, aâ€“z), um Probleme in der `.env`-Datei zu vermeiden.

**Methode 1 â€“ mit Python (einfach & plattformunabhÃ¤ngig)**

Im Repository liegt bereits die Datei `generate_token.py`. FÃ¼hre sie einfach im Projektordner aus:
```bash
python generate_token.py
```
Kopiere den Token, der in der Konsole ausgegeben wird, und fÃ¼ge ihn in deine `.env`-Datei ein.

**Methode 2 â€“ Shell (Linux / macOS / WSL)**
```bash
tr -dc 'A-Za-z' < /dev/urandom | head -c 64 ; echo
```
Den ausgegebenen Token ebenfalls in die `.env`-Datei eintragen.

---

### ğŸ’» API nutzen

**Anfrage**
```http
POST /search
Host: [http://127.0.0.1:8080](http://127.0.0.1:8080)
Authorization: Bearer <DEIN_TOKEN>
Content-Type: application/json

{
  "query": "Tabby Katze",
  "count": 5
}
```

**Antwort (Beispiel)**
```json
[
  {
    "link": "[https://de.wikipedia.org/wiki/Tabby](https://de.wikipedia.org/wiki/Tabby)",
    "title": "Tabby â€“ Wikipedia",
    "snippet": "Tabby bezeichnet die typischen Fellzeichnungen von Katzen..."
  }
]
```

---

## ğŸ¤– In Open WebUI einbinden

ğŸ“š Offizielle Doku: `https://docs.openwebui.com/tutorials/web-search/external`

1.  Gehe zu **Open WebUI â†’ Settings â†’ Web Search**.
2.  Aktiviere **"External Web Search"**.
3.  Trage die Daten ein:
    - **URL:** `http://127.0.0.1:8080/search` (oder die IP deines Docker-Hosts)
    - **Bearer Token:** Dein geheimer Token aus der `.env`-Datei.
4.  Klicke auf **Save**. Fertig!

---

## ğŸ›¡ï¸ Sicherheit & Rate-Limit Tipps
- Setze immer ein starkes **Token** und stelle den Dienst nicht ungeschÃ¼tzt ins Ã¶ffentliche Internet.
- Bei Ã¶ffentlichem Betrieb: Nutze einen **Reverse Proxy** mit zusÃ¤tzlicher Authentifizierung und Rate-Limiting.
- Der Google-Fallback ist ein **Risiko**. Captchas oder IP-Sperren sind mÃ¶glich.
- Die **User-Agent-Rotation** ist aktiv, reduziert aber keine rechtlichen Risiken.

---

## ğŸ§° Troubleshooting

- **401 Unauthorized**: Der `Authorization: Bearer <DEIN_TOKEN>` Header fehlt oder ist falsch.
- **Langsam / keine Ergebnisse**: Gib Tor nach dem Start etwas Zeit. DDG/Google kÃ¶nnen dich trotzdem drosseln oder blockieren.
- **Port-Konflikte**: PrÃ¼fe das Port-Mapping in der `docker-compose.yml`. Die App selbst lauscht im Container auf Port `80`.

---

## ğŸ“œ Lizenz
MIT License Â© 2025 J. Apps

---

## ğŸ†˜ Support & Kontakt

Bei Fragen oder Problemen erreichst du uns hier:

-   **E-Mail:** contact@jappshome.de
-   **Website:** [jappshome.de](https://jappshome.de)
-   **UnterstÃ¼tzung:** [Buy Me a Coffee](https://buymeacoffee.com/J.Apps)